version: 2.2

# Instruct models
# BASE_MODEL: "Qwen2.5-0.5B-Instruct"               # 494M
# BASE_MODEL: "Falcon3-1B-Instruct"                 # 1B
# BASE_MODEL: "Qwen2.5-3B-Instruct"                 # 3B
# BASE_MODEL: "Falcon3-3B-Instruct"
BASE_MODEL: "Falcon3-10B-Instruct"

# any-to-any
MULTILINGUAL: true

# Dataset to use
DATASET_PATH: BounharAbdelaziz/Terjman-v2-English-Darija-Dataset-350K # We use the dataset filtered out from samples containing chinese characters "BounharAbdelaziz/Arabic-Synthetic-Summarization-Dataset"

# Training hyperparameters
hyperparameters:
    num_train_epochs: 2                 # as after 2 we saw a small bump in loss (decreasing)
    lr: 0.0005                           # usually 1e-4 is recommended for Qwen models but as we have a small dataset, we prefer to go slowlier
    batch_size: 4                       # 2 for 0.5B, 1 for 1B, and 2 for 3B LoRA
    gradient_accumulation_steps: 32     # 16 for 0.5B, 32 for 1B
    # eval_accumulation_steps: 3        # to avoid OOM in eval. Slows down eval as it offloads to CPU.
    max_grad_norm: 1.0
    warmup_steps: 500
    warmup_ratio: 0.1

    # LoRA
    USE_LORA: True #False True
    lora_r: 128
    lora_alpha: 64
    lora_dropout: 0.05
    target_modules: 
        - "q_proj"
        - "k_proj"
        - "v_proj"
        - "o_proj"

    # Logging and saving
    logging_steps: 50
    save_steps: 100
    eval_steps: 100

    optimizer: "adamw_torch_fused" # uses less memory. "adamw_torch" and "adamw_torch_fused" for > 1B models to fit in < 15GB VRAM  
    MAX_LEN: 1024 # 1024 or 2048. For 0.5B 2048, and 1024 for > 1B model to fit in < 15GB VRAM

# To observe how the model is performing when we increase the number of training samples
MAX_TRAINING_SAMPLES: 5000 #5000

# Seed for reproducibility
SEED: 42

# metric that indicates best model
METRIC_FOR_BEST_MODEL: "bleu" # as it is particularly useful for evaluating multi-sentence summaries or documents. Indeed, it's a variant of ROUGE-L that splits the text into sentences, computes ROUGE-L for each sentence, and then aggregates the scores.

# precision in training
FP16_TRAINING: True # False

DEFAULT_CHAT_TEMPLATE: "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"

MODELS_DICT:
    Qwen2.5-0.5B-Instruct:
        MODEL_PATH: "Qwen/Qwen2.5-0.5B-Instruct"
        CAUSAL_LM: true
        SFT_TRAINING: true

    Falcon3-1B-Base-SFT:
        MODEL_PATH: "tiiuae/Falcon3-1B-Base"
        CAUSAL_LM: true
        SFT_TRAINING: true

    Falcon3-1B-Instruct:
        MODEL_PATH: "tiiuae/Falcon3-1B-Instruct"
        CAUSAL_LM: true
        SFT_TRAINING: true

    Qwen2.5-3B-Instruct:
        MODEL_PATH: "Qwen/Qwen2.5-3B-Instruct"
        CAUSAL_LM: true
        SFT_TRAINING: true
    
    Falcon3-3B-Instruct:
        MODEL_PATH: "tiiuae/Falcon3-3B-Instruct"
        CAUSAL_LM: true
        SFT_TRAINING: true

    Falcon3-10B-Instruct:
        MODEL_PATH: "tiiuae/Falcon3-10B-Instruct"
        CAUSAL_LM: true
        SFT_TRAINING: true